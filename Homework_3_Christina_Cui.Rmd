---
title: "Homework_3_Christina_Cui"
author: "Christina Cui"
date: "`r Sys.Date()`"
output: html_document
---

### Name: Christina Cui
### UT EID: cc75352
### Github Link: https://github.com/ccui7247/homework3

```{r setup, include = FALSE, message = FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(ggplot2)
library(knitr)
library(mosaic)
setwd('C:/Users/chris/OneDrive/Documents/2023-2024/SDS315/homeworks')

creatinine <- read.csv("creatinine.csv")
market <- read.csv("marketmodel.csv")
covid <- read.csv("covid.csv")
milk <- read.csv("milk.csv")

```


***

## **Problem 1**


### Part A: 

```{r, message = FALSE}

creat_model <- lm(creatclear ~ age, data = creatinine)
new_data <- data.frame(age = 55)

predicted_values <- predict(creat_model, newdata = new_data)
predicted_values <- as.numeric(predicted_values)
print(round(predicted_values, 2))

```

The expected creatinine clearance rate for a 55 year old is around 113.7 mL/minute and I determined this by using the lm() function to find the linear regression model based off the dataset, which produced a linear regression equation of y = 147.81 - 0.62x. Then, I used the predict() function to predict the creatinine clearance rate for a new dataframe with an age value of 55 based off the original linear regression model. 

### Part B:

```{r, message = FALSE}

coefficients <- coef(creat_model)
slope <- coefficients[2]
print(slope)

```

Creatinine clearance rate decreases at a rate of about 0.62 mL/minute every year. I determined this by using the coef() function on the original linear regression equation to find the coefficients of the equation, and then I found the slope by indexing to get the second coefficient, which is a slope of about -0.62. 

### Part C:

```{r, message = FALSE}

age_40 <- data.frame(age = 40)
predicted_40 <- predict(creat_model, newdata = age_40)
resid_40 = 135 - predicted_40
resid_40 <- as.numeric(resid_40)
print(round(resid_40, 2))

age_60 <- data.frame(age = 60)
predicted_60 <- predict(creat_model, newdata = age_60)
resid_60 = 112 - predicted_60
resid_60 <- as.numeric(resid_60)
print(round(resid_60, 2))

```

For the 40 year old, the residual, also known as the difference between observed rate and the expected rate of creatinine clearance is about 11.98, while the residual for the 60 year old is about 1.38. Because the difference between the observed and expected rates of creatinine clearance for the 40 year old is much larger, that means that the 40 year old has a creatinine clearance rate that is 11.98 over the expected creatinine clearance rate for the average 40 year old. On the other hand, the difference between the observed and the expected creatinine clearance rate for the 60 year old is much lower at a value of around 1.38; this means that the 60 year old has a creatinine clearance rate that is only 1.38 over the expected creatinine clearance rate for the average 60 year old. Since the residual for the 40 year old was higher, this means that the 40 year old has a healthier creatinine clearance rate for their age. To calculate the residuals, I first found the predicted creatinine clearance rates for the two people using predict() and the linear regression model I made earlier. Then, I found the residual by subtracting the predicted values from the observed values and compared them to each other to see which residual was bigger and thus, which person had the healthier creatinine clearance rate. 

***

## **Problem 2**


```{r, message = FALSE}
#group by date??? by time period???
apple <- market %>% select(contains("SPY"), contains("AAPL"))
apple_model <- lm(AAPL ~ SPY, data = apple)
coef_apple <- round(coef(apple_model), 2)
apple_r2 <- round(rsquared(apple_model), 2)

google <- market %>% select(contains("SPY"), contains("GOOG"))
google_model <- lm(GOOG ~ SPY, data = google)
coef_google <- round(coef(google_model), 2)
google_r2 <- round(rsquared(google_model), 2)

merck <- market %>% select(contains("SPY"), contains("MRK"))
merck_model <- lm(MRK ~ SPY, data = merck)
coef_merck <- round(coef(merck_model), 2)
merck_r2 <- round(rsquared(merck_model), 2)

johnson <- market %>% select(contains("SPY"), contains("JNJ"))
johnson_model <- lm(JNJ ~ SPY, data = johnson)
coef_johnson <- round(coef(johnson_model), 2)
johnson_r2 <- round(rsquared(johnson_model), 2)

walmart <- market %>% select(contains("SPY"), contains("WMT"))
walmart_model <- lm(WMT ~ SPY, data = walmart)
coef_walmart <- round(coef(walmart_model), 2)
walmart_r2 <- round(rsquared(walmart_model), 2)

target <- market %>% select(contains("SPY"), contains("TGT"))
target_model <- lm(TGT ~ SPY, data = target)
coef_target <- round(coef(target_model), 2)
target_r2 <- round(rsquared(target_model), 2)

ticker <- c("AAPL", "GOOG", "MRK", "JNJ", "WMT", "TGT")
alpha <- c(coef_apple[1], coef_google[1], coef_merck[1], 
                coef_johnson[1], coef_walmart[1], coef_target[1])
beta <- c(coef_apple[2], coef_google[2], coef_merck[2], 
                coef_johnson[2], coef_walmart[2], coef_target[2])
r_squared_values <- c(apple_r2, google_r2, merck_r2, 
                      johnson_r2, walmart_r2, target_r2)
my_tib <- tibble(
  ticker, alpha, beta, r_squared_values
)

print(my_tib)
```
The table above shows the rate of return for the 6 individual stocks based on the return rate of S&P 500, which is the entire stock market. It includes the columns "ticker", which displays the ticker symbols for the 6 individual companies, "alpha", which displays the alpha or the intercept value of the linear regression model, "beta", which displays the beta or the slope value of the linear regression model, and "r_squared_values", which displays the R^2 values for each stock. The R^2 values indicate how well the linear regression models fit the data, with higher R^2 values usually indicating a better fit.

  The beta of the stock is similar to the slope; it measures the rate of change between the overall rate of return of the entire stock market and the rate of return of the individual stock. It measures the relationship between the individual stock and the entire stock market. To calculate the beta of a stock, we would basically calculate for the slope of a linear regression model as normal. I first created a linear regression model for each of the stocks using the lm() function, and then I used the coef() function on those linear regression models to get the alphas (intercepts) and betas (slopes) for each stock's linear regression models. Connecting back to the regression model above, B1 is the beta (slope), and it is multiplying Xt, which is the rate of return of the entire stock market. In order to find Yt, the rate of return of the individual stock, we add the alpha value B0 and the residual et^k to the product of the beta and Xt. This equation shows the change and relationship between the entire stock market's rate of return and the rate of return for individual stocks.

  A higher beta value means higher systematic risk, whereas a lower beta values means a lower systematic risk. This makes sense, as when the entire stock market goes up, stocks with higher beta values will also go up more compared to stocks with lower beta values; on the other hand, when the entire market goes down, the stocks with higher beta values will also go down much more compared stocks with lower beta values, thus illustrating the relationship between beta values and systematic risk. The stock with the lowest systematic risk is the Walmart (WMT) stock, with a beta value of 0.52. The stock with the highest systematic risk is the Apple (AAPL) stock, with a beta value of 1.07. 
  
  
***

## **Problem 3**

```{r, message = FALSE}

italy <- covid %>% filter(country == "Italy") %>%
  select(date, deaths, days_since_first_death)

spain <- covid %>% filter(country == "Spain") %>%
  select(date, deaths, days_since_first_death)

lm_italy <- lm(log(deaths) ~ days_since_first_death, data = italy)
italy_growth <- round(coef(lm_italy)[2], 3)
italy_double <- round(log(2) / italy_growth)

lm_spain <- lm(log(deaths) ~ days_since_first_death, data = spain)
spain_growth <- round(coef(lm_spain)[2], 3)
spain_double <- round(log(2) / spain_growth)

ggplot(covid) + 
   geom_line(aes(x = days_since_first_death, y = log(deaths), color = country)) +
   labs(title = "Covid Growth Rates in Spain and Italy",
       x = "Days Since First Death",
       y = "Number of Deaths (log(death))") 

```

Italy's growth rate is around a rate of 0.183, and its doubling time is around 4 days. Spain has a growth rate of around 0.276, and its doubling time is around 3 days. The line graph above shows the fitted exponential growth models for covid cases in Italy and Spain, coded by color. 

***

## **Problem 4**

```{r, message = FALSE}

lm_milk <- lm(log(sales) ~ log(price), data = milk)

elasticity <- round(coef(lm_milk)[2], 3)

ggplot(milk) + geom_point(aes(x = log(price), y = log(sales))) + 
  geom_abline(intercept = 4.72, slope = -1.619, color='red') + 
  labs(title = "Price Elasticity and Demand of Milk",
       x = "Price of Milk (log(price))",
       y = "Sales of Milk (log(sales))") 
```

The estimated price elasticity for the demand of milk is around -1.619; when the price of milk increases by 1%, the number of sales and thus the demand for the milk will decrease by about 1.62%. To fit the power law relationship, I took the log of both sales and prices and found the coefficients from the equation. The coefficient for the elasticity of the demand of milk is around -1.619.